import os
import uuid
import json
import sys
import logging
from typing import Optional, List, Dict, Any
from vox_unified.gatherer import Gatherer
from vox_unified.datalayer import DataLayer
from vox_unified.embeddings import get_ollama_embedding
from vox_unified.middleware import CacheLayer, TransformerLayer

logger = logging.getLogger("vox-manager")

class VoxManager:
    def __init__(self):
        self.datalayer = DataLayer()
        self.gatherer = Gatherer()
        self.cache = CacheLayer(self.datalayer.local.db_path)

    # --- PROJECT ---
    def project_create(self, path: str, name: Optional[str] = None):
        abs_path = os.path.abspath(path)
        if not os.path.exists(abs_path):
            err = f"‚ùå Error: Path {abs_path} does not exist."
            logger.error(err)
            return err

        existing = self.datalayer.local.get_project_by_path(abs_path)
        if existing:
            msg = f"‚ÑπÔ∏è Project already registered: {existing['name']} (ID: {existing['id']})"
            logger.info(msg)
            return existing['id']

        project_id = uuid.uuid4().hex[:16]
        project_name = name or os.path.basename(abs_path)
        
        self.datalayer.local.add_project(project_id, project_name, abs_path)
        msg = f"‚úÖ Project registered: {project_name} (ID: {project_id})"
        logger.info(msg)
        return project_id

    def project_list(self):
        projects = self.datalayer.local.list_projects()
        if not projects:
            msg = "No projects registered."
            logger.info(msg)
            return msg
        
        projects.sort(key=lambda x: x['name'])
        lines = [f"{ 'Alias':<6} {'ID':<18} {'Name':<20} {'Path'}", "- " * 40]
        env_lines = ["# Auto-generated by VOX CLI"]
        
        for i, p in enumerate(projects):
            alias = f"VX{i}"
            env_lines.append(f"export {alias}={p['id']}")
            lines.append(f"{alias:<6} {p['id']:<18} {p['name']:<20} {p['path']}")
        
        vox_home = os.environ.get("HOME", "")
        env_path = os.path.join(vox_home, ".vox2env")
        completion_block = """
# VOX Zsh Completion
_vox_completion() {
  local -a completions
  local -a response
  response=("${(@f)$(env COMP_WORDS="${words[*]}" COMP_CWORD=$((CURRENT-1)) _VOX_COMPLETE=complete_zsh vox)}")
  for type key descr in ${response}; do
    if [[ "$type" == "plain" ]]; then
      if [[ "$descr" == "_" ]]; then
        completions+=("$key")
      else
        completions+=("$key:$descr")
      fi
    fi
  done
  if [ -n "$completions" ]; then
    _describe -V unsorted completions -U
  fi
}
if command -v compdef > /dev/null; then
  compdef _vox_completion vox
fi
"""
        try:
            with open(env_path, "w") as f:
                f.write("\n".join(env_lines) + "\n")
                f.write(completion_block)
            lines.append("- " * 40)
            lines.append(f"‚ÑπÔ∏è  Aliases updated in {env_path}. Run 'source {env_path}' to apply.", file=sys.stderr)
        except Exception:
            pass

        output = "\n".join(lines)
        print(output, file=sys.stderr)
        return output

    def project_delete(self, project_id: str):
        self.datalayer.local.delete_project(project_id)
        self.datalayer.vector.delete_project_data(project_id)
        self.cache.invalidate(project_id)
        msg = f"‚úÖ Deleted project {project_id}"
        print(msg, file=sys.stderr)
        return msg

    def project_stats(self, project_id: str):
        return "Stats not implemented yet."

    # --- INDEX ---
    def index_run(self, project_id: str, force: bool = False):
        project = self.datalayer.local.get_project(project_id)
        if not project:
            msg = f"‚ùå Project {project_id} not found."
            print(msg, file=sys.stderr)
            return msg

        print(f"üöÄ Indexing {project['name']}...", file=sys.stderr)
        
        self.datalayer.vector.delete_project_data(project_id)
        self.cache.invalidate(project_id)

        # Re-cache tree
        self.get_project_tree(project_id)

        items = self.gatherer.scan_project(project['path'])
        
        local_docs = self.datalayer.local.list_documents(project_id)
        for doc in local_docs:
            items.append({
                "content": f"Title: {doc.get('title')}\n{doc['content']}",
                "file_path": "local_db",
                "type": doc['type'],
                "metadata": {"doc_id": doc['id']}
            })

        if items:
            print(f"Embedding {len(items)} items...", file=sys.stderr)
            embeddings = [get_ollama_embedding(item["content"][:1000], is_query=False) for item in items]
            self.datalayer.vector.save_to_index(items, project_id, embeddings)
            
        return f"‚úÖ Indexing complete. {len(items)} items saved."

    # --- SEARCH ---
    def search_run(self, project_id: Optional[str] = None, query: Optional[str] = None, limit: int = 20):
        if query is None:
            query = project_id
            project_id = None
        
        if not query:
            return "‚ùå Error: Search query is required."

        print(f"\n[üîç SEARCH: '{query}']", file=sys.stderr)
        print("-" * 80, file=sys.stderr)

        emb = get_ollama_embedding(query, is_query=True)
        hits = self.datalayer.vector.search(query, emb, project_id, limit)
        
        seen_content = set()
        unique_hits = []
        for r in hits:
            if r.content in seen_content: continue
            
            # SMART SNIPPET: Center around the match
            full_content = r.content.replace('\n', ' ').strip()
            match_idx = full_content.lower().find(query.lower())
            
            if match_idx != -1:
                start = max(0, match_idx - 60)
                end = min(len(full_content), match_idx + 140)
                snippet = ("..." if start > 0 else "") + full_content[start:end] + ("..." if end < len(full_content) else "")
            else:
                snippet = full_content[:200] + "..."
            
            # Traceability: Path + Line
            source_tag = f"[{r.type.upper()}] {r.source}"
            print(f"  {r.relevance:.2f} | {source_tag}", file=sys.stderr)
            print(f"       > {snippet}", file=sys.stderr)
            print("-" * 80, file=sys.stderr)
            
            seen_content.add(r.content)
            unique_hits.append({
                "relevance": round(r.relevance, 2),
                "source": r.source,
                "type": r.type,
                "content": r.content
            })
                
        return unique_hits

    # --- ASK ---
    def ask_run(self, question: str, project_id: str, model: Optional[str] = None, reset_history: bool = False):
        emb = get_ollama_embedding(question, is_query=True)
        hits = self.datalayer.vector.search(question, emb, project_id, 5)
        
        context = "### PROJECT CONTEXT\n"
        for r in hits:
            context += f"Source: {r.source} ({r.type})\nContent: {r.content}\n---\n"
            
        import ollama
        resp = ollama.chat(model=model or "gemma3:4b-it-qat", messages=[{"role": "user", "content": f"Question: {question}\n\nContext:\n{context}"}])
        answer = resp['message']['content']
        print(f"\n[ü§ñ VOX]: {answer}", file=sys.stderr)
        return answer

    # --- DOCS ---
    def docs_add(self, project_id: str, content: str, title: Optional[str] = None, type: str = "note"):
        doc_id = self.datalayer.local.add_document(project_id, type, content, title)
        item = {
            "content": f"Title: {title}\n{content}" if title else content,
            "file_path": "local_db",
            "type": type,
            "metadata": {"doc_id": doc_id}
        }
        emb = get_ollama_embedding(item["content"][:1000], is_query=False)
        self.datalayer.vector.save_to_index([item], project_id, [emb])
        print(f"‚úÖ Saved doc (ID: {doc_id})", file=sys.stderr)
        return doc_id

    def docs_list(self, project_id: str):
        docs = self.datalayer.local.list_documents(project_id)
        lines = []
        for d in docs:
            line = f"[{d['id']}] {d['type'].upper()}: {d['title'] or 'No Title'}"
            lines.append(line)
        
        output = "\n".join(lines) if lines else "No docs found."
        print(output, file=sys.stderr)
        return output

    # --- UTILS ---
    def get_project_tree(self, project_id: str):
        cached = self.cache.get(project_id, "file_tree")
        if cached: return cached
        proj = self.datalayer.local.get_project(project_id)
        if not proj: return "Not found"
        tree = []
        for root, dirs, files in os.walk(proj['path']):
            dirs[:] = [d for d in dirs if d not in self.gatherer.IGNORE_DIRS]
            level = root.replace(proj['path'], '').count(os.sep)
            tree.append(f"{ ' ' * 4 * level}{os.path.basename(root)}/")
            for f in files: tree.append(f"{ ' ' * 4 * (level + 1)}{f}")
        res = "\n".join(tree)
        self.cache.set(project_id, "file_tree", res)
        return res

    def get_file_skeleton(self, project_id: str, file_path: str):
        proj = self.datalayer.local.get_project(project_id)
        if not proj: return "Not found"
        abs_path = os.path.join(proj['path'], file_path)
        if not os.path.exists(abs_path): return "Not found"
        with open(abs_path, 'r') as f:
            return TransformerLayer.generate_skeleton(f.read(), file_path)

    # --- SERVER ---
    def server_start(self, verbose: bool = False):
        from vox_unified.mcpserver import run
        if verbose:
            print("üöÄ Starting VOX Unified MCP Server in VERBOSE mode...", file=sys.stderr)
        else:
            print("üöÄ Starting VOX Unified MCP Server...", file=sys.stderr)
        run(verbose=verbose)
